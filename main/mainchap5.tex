\chapter{The Simulation Mapping}
\label{chap:equiv_mapping}

The definition of round simulation in~\cref{chap:round_equivalence} consists of existential statements: it considers the existence of words $x'$ that satisfy the requirement of round simulation.
However, our framework lacks an additional feature -- we settle for $x'$ to \emph{exist}, but that does not mean we can actually compute it. In some cases, being able to calculate it is beneficial; in other cases, it is necessary.

Computing $x'$ has several benefits. Consider the monitor from~\cref{example:MC_rounds}. We have modelled it by a transducer $\cT_1$ and presented a simpler transducer $\cT_2$ that round simulated $\cT_1$, which allowed us then to verify a desired property on $M$ against the much smaller $\cT_2$: ``if there is no \texttt{error}, then Process $3$ works at least once every 20 steps''.
% Consider now the slightly changed property: ``if there is no \texttt{error} \emph{and Process 1 works on the first step}, then Process $3$ works at least once every 20 steps''. In this case, it refers to a subset of inputs; thus, to use $\cT_2$ again, we need to know the subset of permuted inputs that we need to check against.
The way the verification is performed under simulation is by rewriting the property in a way that exploits the simpler behaviour of $\cT_2$. For instance, since we know that $\cT_2$ expects to see the requests in the order of the process IDs, then in particular in the case of no \texttt{error}, in every round of length $10$ the third letter must be $\{3\}$. Then we can rewrite the property in terms of $\cT_2$ in the following manner:
``if there is no \texttt{error}, then for all $n\in\bbN$, the input must have $\{3\}$ in one of the indices $20n+3$ and $20n+13$''.
An algorithm could then be designed to verify this more specific property.
Observe that to rewrite the property we needed some insight on the behaviour of $\cT_2$; specifically, we had to know the structure of $x'$ for any input $x$ that satisfies the premise of the property.

We showed an example of a case where we need be able to calculate $x'$ for verification of properties. Generally, being able to compute $x'$ has the additional benefit of $\emph{explainability}$: it allows us to give a solid reason for the verification result. For instance, if some property does not hold for $x$, a developer might want to get insight
% on the reason for the failure
by computing the run of $\cT_2$ on $x'$, instead of the possibly much more expensive computation of the run of $\cT_1$ on $x$.
It turns out that, in the general sense, calculating $x'$ is not a simple task.

Consider two transducers $\cT_1$ and $\cT_2$ such that $\cT_1 \prec_{k} \cT_2$, and an input word $x\in \left(\sI^k\right)^*$. This means, by definition, that there is a way to permute the rounds in $x$ to obtain a word $x'$ such that $\cT_2(x')$ is a permutation of $\cT_1(x)$.
Consider then a mapping $\psi_{\cT_1,\cT_2}: x\mapsto x'$ that maps every input word $x$ to a corresponding round equivalent word $x'$ (and we drop the subscript when the transducers are clear from context). We call this a \emph{simulation~mapping between $\cT_1$ and $\cT_2$}. In this section we study this mapping and present some properties that it does or does not satisfy. We begin with an example.

\begin{example}
\label{example:mapping}
Consider the transducers $\cT_1$ and $\cT_2$ depicted in~\cref{fig:example_mapping}, with input and output alphabets $\sI=\{a,b\}$ and $\sO=\{0,1\}$. $\cT_1$ expects to see either $ab$ or $ba$ in every round, outputting $00$ in both cases, and otherwise outputs $01$ in that round. $\cT_2$ expects the first round to be $ab$ and the second to be $ba$, otherwise outputs $01$ in the round not meeting expectations; and beginning from the third round, it behaves like $\cT_1$. We have that $\cT_1\prec_{2}\cT_2$ by a permutation that corrects the order of the letters in the first two rounds of the input. Moreover, we have $\psi(ab)= \psi(ba)=ab$ whereas $\psi(abba)=abba \neq \psi(ab) \cdot \psi(ba)$.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm and 1.5cm,on grid,auto]
	    \tikzset{every state/.style={minimum size=7mm}};
	    \node[state] (q'_i) [initial above, text=red, fill=blue!10] {$0$};
        \node[state] (q'_ab) [right=of q'_i, text=red, fill=blue!10] {$0$};
        \node[state] (q'_ba) [below=of q'_i, text=red, fill=blue!10] {$0$};
        \node[state] (q'_f) [below=of q'_ab, text=red, fill=blue!10] {$1$};
        \path[->] 
        (q'_i)  edge [bend left=10] node {$a$} (q'_ab)
        (q'_i)  edge [bend left=10] node {$b$} (q'_ba)
        (q'_ab) edge [bend left=10] node {$a$} (q'_f)
        (q'_ab) edge [bend left=10] node {$b$} (q'_i)
        (q'_ba) edge [bend left=10] node {$a$} (q'_i)
        (q'_ba) edge [bend left=10] node {$b$} (q'_f)
        (q'_f)  edge [bend left=10] node {$a$} (q'_ab)
        (q'_f)  edge [bend left=10] node {$b$} (q'_ba);
	    
        \node[state] (q_0) [initial above, right=of q'_ab, text=red] {};
        \node[state] (q1_a) [right=of q_0, text=red, fill=red!10] {$0$};
        \node[state] (q1_b) [below right=of q_0, text=red, fill=red!10] {$0$};
        \node[state] (q1_ab) [right=of q1_a, text=red, fill=red!10] {$0$};
        \node[state] (q1_ba) [right=of q1_b, text=red, fill=red!10] {$1$};
        \node[state] (q2_b) [right=of q1_ab, text=red, fill=green!10] {$0$};
        \node[state] (q2_a) [right=of q1_ba, text=red, fill=green!10] {$0$};
        \node[state] (q2_ba) [right=of q2_b, text=red, fill=green!10] {$0$};
        \node[state] (q2_ab) [right=of q2_a, text=red, fill=green!10] {$1$};
        \node[state] (q_i) [right=of q2_ba, text=red, fill=blue!10] {$0$};
        \node[state] (q_ab) [right=of q_i, text=red, fill=blue!10] {$0$};
        \node[state] (q_ba) [right=of q2_ab, text=red, fill=blue!10] {$0$};
        \node[state] (q_f) [right=of q_ba, text=red, fill=blue!10] {$1$};
        \path[->] 
        (q_0)   edge [] node {$a$} (q1_a)
        (q_0)   edge [sloped, pos=0.2] node {$b$} (q1_b)
        (q1_a)  edge [sloped, pos=0.2] node {$a$} (q1_ba)
        (q1_a)  edge [] node {$b$} (q1_ab)
        (q1_b)  edge [] node {$a,b$} (q1_ba)
        (q1_ab) edge [sloped, pos=0.2] node {$a$} (q2_a)
        (q1_ab) edge [] node {$b$} (q2_b)
        (q1_ba) edge [] node {$a$} (q2_a)
        (q1_ba) edge [sloped, pos=0.2] node {$b$} (q2_b)
        (q2_a)  edge [] node {$a,b$} (q2_ab)
        (q2_b)  edge [] node {$a$} (q2_ba)
        (q2_b)  edge [sloped, pos=0.2] node {$b$} (q2_ab)
        (q2_ab) edge [out=-30, in=-50, sloped, looseness=2, below] node {$a$} (q_ab)
        (q2_ab) edge [] node {$b$} (q_ba)
        (q2_ba) edge [out=30,in=140, sloped] node {$a$} (q_ab)
        (q2_ba) edge [sloped, pos=0.2] node {$b$} (q_ba)
        (q_i)   edge [bend left=10] node {$a$} (q_ab)
        (q_i)   edge [bend left=10] node {$b$} (q_ba)
        (q_ab)  edge [bend left=10] node {$a$} (q_f)
        (q_ab)  edge [bend left=10] node {$b$} (q_i)
        (q_ba)  edge [bend left=10] node {$a$} (q_i)
        (q_ba)  edge [bend left=10] node {$b$} (q_f)
        (q_f)   edge [bend left=10] node {$a$} (q_ab)
        (q_f)   edge [bend left=10] node {$b$} (q_ba);
    \end{tikzpicture}
	\caption{The transducers $\cT_1$ (left) and $\cT_2$ (right) in~\cref{example:mapping}. The states of $\cT_2$ in red, green and blue manage the first, second and later rounds, respectively.}
	\label{fig:example_mapping}
\end{figure}
\end{example}

\Cref{example:mapping} shows that $\psi$ is not a homomorphism: it does not satisfy $\psi(xy)=\psi(x)\psi(y)$. Next, we show that $\psi$ cannot be described by a look-ahead machine, i.e. one that reads a ``compound'' of rounds in every step.

\begin{example}
\label{example:lookahead}
Set $\fL=L[ab\cdot (cc)^*\cdot (ab+ba)]$ and $k=2$, and let $\cT_1$ and $\cT_2$ be the transducers in~\cref{fig:example_lookahead}, satisfying $\cT_1\prec_{k,\fL} \cT_2$. Denote the simulation mapping by $\psi^*: (\sI^k)^* \rightarrow (\sI^k)^*$.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm and 1.5cm,on grid,auto]
	    \tikzset{every state/.style={minimum size=7mm}};
	    \node[state] (q_0)  [initial above, text=red] {};
        \node[state] (q_a) [right=of q_0, text=red] {$1$};
        \node[state] (q_b) [below=of q_a, text=red] {$1$};
        \node[state] (q'_0) [right=of q_a, text=red, fill=orange!20] {$2$};
        \node[state] (q'_a) [right=of q'_0, text=red] {$3$};
        \node[state] (q'_b) [below=of q'_a, text=red] {$5$};
        \node[state] (q'_ab) [right=of q'_a, text=red] {$4$};
        \node[state] (q'_ba) [right=of q'_b, text=red] {$6$};
        \path[->] 
        (q_0)  edge [] node {$a$} (q_a)
        (q_0)  edge [sloped] node {$b$} (q_b)
        (q_a) edge [] node {$b$} (q'_0)
        (q_b) edge [sloped] node {$a$} (q'_0)
        (q'_0) edge [loop above] node {$c$} (q'_0)
        (q'_0) edge [] node {$a$} (q'_a)
        (q'_0) edge [sloped] node {$b$} (q'_b)
        (q'_a) edge [] node {$b$} (q'_ab)
        (q'_b) edge [] node {$a$} (q'_ba);
    \end{tikzpicture}%
    \hspace{1.5cm}%
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm and 1.5cm,on grid,auto]
	    \tikzset{every state/.style={minimum size=7mm}};
	    \node[state] (q_0)  [initial above, text=red] {};
        \node[state] (q_a) [right=of q_0, text=red] {$1$};
        \node[state] (q_b) [below=of q_a, text=red] {$1$};
        \node[state] (q'_0) [right=of q_a, text=red, fill=orange!20] {$2$};
        \node[state] (q'_1) [right=of q_b, text=red, fill=orange!20] {$2$};
        \node[state] (q'_a) [right=of q'_0, text=red] {$3$};
        \node[state] (q'_b) [below=of q'_a, text=red] {$5$};
        \node[state] (q'_ab) [right=of q'_a, text=red] {$4$};
        \node[state] (q'_ba) [right=of q'_b, text=red] {$6$};
        \path[->] 
        (q_0)  edge [] node {$a$} (q_a)
        (q_0)  edge [sloped] node {$b$} (q_b)
        (q_a) edge [] node {$b$} (q'_0)
        (q_b) edge [] node {$a$} (q'_1)
        (q'_0) edge [loop above] node {$c$} (q'_0)
        (q'_1) edge [loop above] node {$c$} (q'_1)
        (q'_0) edge [] node {$a$} (q'_a)
        (q'_1) edge [] node {$b$} (q'_b)
        (q'_a) edge [] node {$b$} (q'_ab)
        (q'_b) edge [] node {$a$} (q'_ba);
    \end{tikzpicture}
	\caption{The transducers $\cT_1$ (left) and $\cT_2$ (right) in~\cref{example:lookahead}.}
	\label{fig:example_lookahead}
\end{figure}

We claim that for any $r$, there is no look-ahead machine that defines a function $\psi_r: (\sI^{rk})^* \rightarrow (\sI^{rk})^*$ such that $\psi^*(x)=\psi(x)$ for all input words $x$.

Indeed, let $r\in\bbN$, and assume by way of contradiction that such $\psi_r$ exists. Now consider the input word $x=ab\cdot c^{rk-2}$. $\psi_r(x)$ must start with either $ab$ or $ba$. Without loss of generality, assume the former, and consider the input word $x':=x\cdot ba\cdot c^{rk-2}$. Since $\psi_r$ works on $r$ rounds each time, the first $r$ rounds are fixed when it reads the $(r+1)$-th round. Moreover, since $\psi_r(x')$ must induce a valid path in $\cT_2$, the only option for the $(r+1)$-th round of $\psi_r(x')$ is $ab$. Hence, the output of $\cT_1$ on $x'$ is different from the output of $\cT_2$ on $\psi(x')$, and we have a contradiction.
\end{example}

% This example only works if we assume that $\psi_r$ is ``ignorant'' of the fact that, actually, we will \emph{never} want to shuffle the very first round to be $ba$. This is a piece of knowledge so simple that it might not be practically reasonable to have it hidden from $\psi_r$.

% The example can be extended to any round length $k$; and it is possible to get rid of the restriction language $\fL$, as well. See the generalized transducers below (``Dec 21$^\text{st}$'').

In~\cref{example:lookahead}, we used the definition of round simulation with restriction; however, it is indeed possible to get rid of the restriction language $\fL$ -- it was kept for clarity. Moreover, the example uses a round length of $k=3$, but it can be extended to any round length $k>0$ in a similar manner.

We showed that a look-ahead of $r$ rounds does not suffice for any $r$.
% A look-ahead of a number not divisible by $k$ will not work either, since we must at least read the whole round to know the correct way to shuffle.
Moreover, a sliding-window variation of the look-ahead model, in which at any given round the machine can read $r-1$ additional rounds in the future, would not give any additional benefit either; in fact, the same pair of transducers in~\cref{example:lookahead} show that it is generally impossible to determine the output of the first round without knowing the entire input.
% Indeed, even if we know the future beforehand, it does not permit us to rewrite the past, so a wrong choice in the first round would not be fixed. Hence, no look-ahead or sliding-window machine can define $\psi^*$.

Currently, the best algorithm we have for computing $\psi$ is straight-forward: for an input $x$, we iterate over all round equivalent words $x'\req[k] x$ and check for satisfaction of $\cT_1(x) \req[k] \cT_2(x')$. Since the length of inputs is unlimited, this algorithm can only be modelled by a Turing machine.
The question of whether $\psi$ can be defined by a simpler finite-state model remains open.

% In fact, it would be possible to effectively ``rewrite'' the past by permitting delayed output. A finite-state machine supporting delayed output would be enough for the $\psi^*$ of the last example: the machine would read the input round-by-round, searching for two rounds of the form $a^{k-2}\left(ab+ba\right)$ (not necessarily consecutive). Once they are detected, it would decide the output for the \emph{first} of them according to the second. Deciding the remainder of the output is simple.
